# INTRODUZIONE 
L'obiettivo principale dell'industria dei computer è sempre stata quella di voler aumentare le performance, in passato si faceva aumentando il clock ma poi divenne impossibile per un limite fisico ovvero che un segnale non può essere più veloce della velocità della luce e per problemi di gestione delle temperature. un computer con un clock a $1 THz$ deve essere più piccolo di 100 $\mu m$ per dare abbastanza spazio al singolo ciclo di clock è fattibile ma ci sono comunque limiti strutturali di dissipazione del calore una soluzione a questo problema é l'architettura parallela ovvero più CPU che collaborano per il medesimo obiettivo 
# Classificazione di Flynn 
ci permette di classificare i tipi di architetture in base a flusso di istruzioni e flusso di dati 
![[Pasted image 20240508142020.png]]

# Classificazione dei calcolatori 
![[Pasted image 20240508142038.png]]

# ARCHITETTURE PER IL CALCOLO PARALLELO 
Il parallelismo aiuta appunto a migliorare le performance con tecnologie come il pipelining e le architetture superscalari si può arrivare ad un miglioramento dal 5 al 10. Con più CPU si arriva a un miglioramento addirittura dal 50 al 100% esistono tre approcci riguardo queste architetture: - Data parallel computers(SIMD) - Multiprocessors (MIMD) - Multicomputers (MIMD) 

# Le varie architetture 
![[Pasted image 20240508142047.png]]
# Parallelismo nel chip 
Può avvenire in 3 modi: 
### Parallelismo a livello di istruzioni 
mettere più istruzioni per ogni ciclo di clock con due tipi di processori: 
- Superscalari con pipeline e unità funzionali parallele 
![[Pasted image 20240508142117.png]]

- Processori VLIW con istruzioni lunghe che dividono il problema nelle varie componenti 
![[Pasted image 20240508142128.png]]

## Multithreading nel chip 
Risolve un problema di stallo della pipeline, ovvero quando una CPU tenta di accedere ad una informazione in memoria e non nella cache e perciò per accedervi ha bisogno di tempo per caricarla prima di riprendere l'esecuzione. 
Il multithreading si divide in 3 approcci: 
- a grana fine 
- a grana grossa 
- di tipo simultaneo

>[!tip]- Prerequisito, che cos'è un Thread?
>È uno spezzettamento di un'istruzione in due o più parti, dette processi.
# Il problema dello stato della pipeline
Supponiamo di avere una CPU che emette una istruzione per ciclo di clock con tre thread A, B, C, che durante il primo ciclo eseguono le istruzioni A1, B1, C1.
Durante il secondo ciclo A2 fa un riferimento non presente nella cache del primo livello e deve attendere 2 cicli per recuperarlo dalla cache di secondo livello.
![[Pasted image 20240508144711.png]]

## Multithreading a grana fine
Tutte le singole istruzioni dei thread sono eseguire ogni ciclo di clock, a turno.
![[Pasted image 20240508151050.png]]
- Nei due cicli di stallo la CPU è occupata a svolgere le istruzioni degli altri due thread.
- Ogni Thread ha il proprio insieme di registri che sono definiti a priori in fase di progettazione del chip.
- Nella pipeline non ci sarà mai più di una istruzione per thread e quindi il numero massimo di thread è pari al numeri di stadi della pipeline.

## Multithreading a grana grossa
Un thread va avanti finché 
- non raggiunge uno stallo
- perde un ciclo
- commuta su un altro thread
![[Pasted image 20240508151646.png]]
Esiste una variante che permette di "guardare avanti" le istruzioni anticipando lo stallo e approssimando il multithreading a grana fine.

## Multithreading in CPU superscalari
Le CPU possono avere più unità in parallelo ed emettere più istruzioni per ciclo.
![[Pasted image 20240508160442.png]]

### Multithreading parallelo
Ciascun thread emette due istruzioni per ciclo fintanto che può, altrimenti, non appena raggiunge uno stallo, viene emessa immediatamente un’istruzione del thread che segue affinché la CPU resti pienamente impegnata.

QUESTO ACCADE CON MULTITHREADING A GRANA FINE E GROSSA
![[Pasted image 20240508163222.png]]

QUESTO ACCADE CON MULTITHREADING SIMULTANEO
![[Pasted image 20240508163247.png]]
Se noti gli stalli della prima tabella sono riempiti.

# Multiprocessori in un solo chip
Dato che fisicamente non è possibile incrementare la sequenza di clock per ottenere CPU più veloci, le industrie produttrici di chip hanno incominciato ad inserire più CPU (chiamate core) all'interno dello stesso chip (o meglio die).

I multiprocessori possono essere realizzati
- con core identici (multiprocessori omogenei)
- con core con specifiche funzionalità (multiprocessori eterogenei)

## Multiprocessori omogenei
I multiprocessori condividono la cache di primo e secondo livello e la memoria principale.

Si dividono in altre due sotto categorie:
1. Quelle con una sola CPU e più pipeline che possono moltiplicare il throughtput in base al numero di pipeline. 
2. Quelle che hanno più CPU (core) ciascuna con la propria pipeline.

Il processo di ***snooping*** (eseguito dall'hardware) garantisce che se una paro,a è presente in più cach e una CPU modifica il suo valore in memoria, essa è automaticamente rimossa in tutte le cache in modo da garantire consistenza.

# Multiprocessori Eterogenei
Un tipo di multicore in cui ogni core ha un compito specifico: poiché queste architetture realizzano un vero e proprio calcolatore completo in un signolo chip sono spesso dette ***system on a chip***.

# Chip-level Multiprocessor
I chip multicore sono come dei piccoli multiprocessori e per questa ragione vengono chiamati CMP.
Sfruttare questi chip prevede l'uso di algoritmi che hanno un uso in parallelo e sono molto complessi da realizzare per i chip multicore. Per farli comunicare tra loro viene usato un bus, ma per i sistemi più grandi ne serve più di uno o ad anello: l'anello è un sistema che fa comunicare i core tutti insieme collegandoli due a due formando un anello per poter trasmettere dei dati da core a core si usa un token che viene preso dalla singola cpu, quando lo prende può trasferire le informazioni e una volta riposto il token qualche altra cpu può prenderlo (tipo gioco delle sedie) il bus è frutto dell'interconnessione delle cpu quindi una cpu può passare le informazioni tra le cpu.

